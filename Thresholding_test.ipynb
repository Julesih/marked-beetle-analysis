{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thresholding_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aeDa7wB_oOhYRMl0K9bz1D_HvxQXvk37",
      "authorship_tag": "ABX9TyMcMHklnKrPr+tMj2SmCq9p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julesih/marked-beetle-analysis/blob/main/Thresholding_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFnRAG5-dJaN"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n1Orcf7dYLT"
      },
      "source": [
        "def threshcrop(img):\n",
        "  #convert to grayscale and apply adaptive thresholding\n",
        "  grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
        "  blur = cv2.GaussianBlur(grayscale,(5,5),0).astype('uint8')\n",
        "  retval,thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "  \n",
        "  #thresh = thresh[:,:,None]\n",
        "  #return thresh\n",
        "\n",
        "  #detect edges and crop the image\n",
        "  canny = cv2.Canny(thresh, 50, 200)\n",
        "  pts = np.argwhere(canny > 0)\n",
        "  y1,x1 = pts.min(axis=0)\n",
        "  y2,x2 = pts.max(axis=0)\n",
        "  cropped_img = thresh[y1:y2, x1:x2]\n",
        "  cropped_img = cropped_img[:,:,None]\n",
        "  return cropped_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLIuo0k8dh3I"
      },
      "source": [
        "\n",
        "image=cv2.imread('drive/MyDrive/MarkedBeetleImageAnalysis/PaperedControl8d.tif')\n",
        "cv2_imshow(threscrop(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrknEdCKe5M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d784ac0-3721-4b62-8db8-9ee48aa99196"
      },
      "source": [
        "import os\n",
        "filenames = os.listdir(\"/content/drive/MyDrive/MarkedBeetleImageAnalysis\")\n",
        "filenames[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PaperedControl21v.tif',\n",
              " 'PaperedControl21v_light.tif',\n",
              " 'PaperedControl21d.tif',\n",
              " 'PaperedControl21d_light.tif',\n",
              " 'PaperedControl22v.tif']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6u8ax2yWpCA"
      },
      "source": [
        "#IMG_SIZE=1000\n",
        "\n",
        "def threshold(img):\n",
        "  #convert to grayscale and apply adaptive thresholding\n",
        "  grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
        "  blur = cv2.GaussianBlur(grayscale,(5,5),0).astype('uint8')\n",
        "  retval,thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "  thresh = thresh[:,:,None]\n",
        "  return thresh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "BeFndau4pMS-",
        "outputId": "a4b8a672-d982-4484-a164-4a9a162462ec"
      },
      "source": [
        "for i in filenames:\n",
        "  image=cv2.imread('drive/MyDrive/MarkedBeetleImageAnalysis/'+i)\n",
        "  new_image=threshold(image)\n",
        "\n",
        "  cv2.imwrite(f'drive/MyDrive/GrayscaleThresholdBeetleImages/{i}', new_image)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-4ba61c500132>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/MarkedBeetleImageAnalysis/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mnew_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'drive/MyDrive/GrayscaleThresholdBeetleImages/{i}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-ce067d047a9a>\u001b[0m in \u001b[0;36mthreshold\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#convert to grayscale and apply adaptive thresholding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mgrayscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTHRESH_OTSU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5orshwTqn9Cv"
      },
      "source": [
        "for j in filenames[1000:]: #ignore 997, 998, and 999\n",
        "  image=cv2.imread('drive/MyDrive/MarkedBeetleImageAnalysis/'+j)\n",
        "  new_image=threshold(image)\n",
        "\n",
        "  cv2.imwrite(f'drive/MyDrive/GrayscaleThresholdBeetleImages/{j}', new_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGGIBQAWyTj0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzk62G4z2G4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}